{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "young-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "from haystack.preprocessor.cleaning import clean_wiki_text\n",
    "from haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\n",
    "from haystack.reader.farm import FARMReader\n",
    "from haystack.reader.transformers import TransformersReader\n",
    "from haystack.utils import print_answers\n",
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "increased-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2021 13:37:28 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.075s]\n",
      "03/13/2021 13:37:28 - INFO - elasticsearch -   GET http://localhost:9200/document [status:200 request:0.004s]\n",
      "03/13/2021 13:37:28 - INFO - elasticsearch -   PUT http://localhost:9200/document/_mapping [status:200 request:0.027s]\n",
      "03/13/2021 13:37:28 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.002s]\n"
     ]
    }
   ],
   "source": [
    "# connect to ES, create indexes\n",
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")\n",
    "\n",
    "# to delete created indexes later on use:\n",
    "# curl -XDELETE localhost:9200/label\n",
    "# curl -XDELETE localhost:9200/document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "concerned-inspiration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2021 13:37:31 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.135s]\n"
     ]
    }
   ],
   "source": [
    "# add data to ES\n",
    "\n",
    "from lxml import etree\n",
    "from lxml.etree import tostring\n",
    "\n",
    "input_file_path = \"data/Wikipedia-Strength-Training.xml\"\n",
    "\n",
    "\n",
    "tree = etree.parse(input_file_path)\n",
    "root = tree.getroot()\n",
    "# iterate through all the titles\n",
    "\n",
    "document_dictionaries = []\n",
    "for text_node in root.findall(\".//text\", namespaces=root.nsmap)[:20]:\n",
    "    document_dictionaries.append({'text': text_node.text, 'meta': None})\n",
    "\n",
    "document_store.write_documents(document_dictionaries)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "naked-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize retriever\n",
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "retriever = ElasticsearchRetriever(document_store=document_store)\n",
    "\n",
    "# luke_tokenizer = AutoTokenizer.from_pretrained(\"nielsr/luke-large\")\n",
    "\n",
    "# luke_model = AutoModel.from_pretrained(\"nielsr/luke-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "instrumental-vermont",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2021 13:37:46 - INFO - farm.utils -   Using device: CPU \n",
      "03/13/2021 13:37:46 - INFO - farm.utils -   Number of GPUs: 0\n",
      "03/13/2021 13:37:46 - INFO - farm.utils -   Distributed Training: False\n",
      "03/13/2021 13:37:46 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "03/13/2021 13:37:56 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "03/13/2021 13:37:56 - INFO - farm.utils -   Using device: CPU \n",
      "03/13/2021 13:37:56 - INFO - farm.utils -   Number of GPUs: 0\n",
      "03/13/2021 13:37:56 - INFO - farm.utils -   Distributed Training: False\n",
      "03/13/2021 13:37:56 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/13/2021 13:37:56 - INFO - farm.infer -   Got ya 11 parallel workers to do inference ...\n",
      "03/13/2021 13:37:56 - INFO - farm.infer -    0    0    0    0    0    0    0    0    0    0    0 \n",
      "03/13/2021 13:37:56 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\\n",
      "03/13/2021 13:37:56 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\\n",
      "03/13/2021 13:37:56 - INFO - farm.infer -                       \n"
     ]
    }
   ],
   "source": [
    "# initialize reader\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "concerned-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "\n",
    "from haystack.pipeline import ExtractiveQAPipeline\n",
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "congressional-integrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2021 13:38:03 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.127s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.84s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.63s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.67s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.67s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.76s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.81s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.89s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.83s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.22s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.28s/ Batches]\n",
      "03/13/2021 13:39:34 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.015s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.55s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.54s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.08s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.94s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:12<00:00,  6.01s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:12<00:00,  6.06s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.95s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.07s/ Batches]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "prediction1 = pipe.run(query=\"What is stamina?\", top_k_retriever=10, top_k_reader=5)\n",
    "\n",
    "prediction2 = pipe.run(query=\"How to avoid injury?\", top_k_retriever=10, top_k_reader=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get answers\n",
    "print(\"Question 'What is stamina?'\")\n",
    "print_answers(prediction1, details=\"minimal\")\n",
    "print(\"Question 'How to avoid injury?'\")\n",
    "print_answers(prediction2, details=\"minimal\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
