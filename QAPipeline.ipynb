{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "young-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "from haystack.preprocessor.cleaning import clean_wiki_text\n",
    "from haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\n",
    "from haystack.reader.farm import FARMReader\n",
    "from haystack.reader.transformers import TransformersReader\n",
    "from haystack.utils import print_answers\n",
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "increased-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2021 13:48:47 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.008s]\n",
      "03/13/2021 13:48:47 - INFO - elasticsearch -   GET http://localhost:9200/document [status:200 request:0.002s]\n",
      "03/13/2021 13:48:47 - INFO - elasticsearch -   PUT http://localhost:9200/document/_mapping [status:200 request:0.012s]\n",
      "03/13/2021 13:48:47 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.004s]\n"
     ]
    }
   ],
   "source": [
    "# connect to ES, create indexes\n",
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")\n",
    "\n",
    "# to delete created indexes later on use:\n",
    "# curl -XDELETE localhost:9200/label\n",
    "# curl -XDELETE localhost:9200/document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "concerned-inspiration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2021 13:48:49 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.448s]\n"
     ]
    }
   ],
   "source": [
    "# add data to ES\n",
    "\n",
    "from lxml import etree\n",
    "from lxml.etree import tostring\n",
    "\n",
    "input_file_path = \"data/Wikipedia-Strength-Training.xml\"\n",
    "\n",
    "\n",
    "tree = etree.parse(input_file_path)\n",
    "root = tree.getroot()\n",
    "# iterate through all the titles\n",
    "\n",
    "document_dictionaries = []\n",
    "for text_node in root.findall(\".//text\", namespaces=root.nsmap)[:20]:\n",
    "    document_dictionaries.append({'text': text_node.text, 'meta': None})\n",
    "\n",
    "document_store.write_documents(document_dictionaries)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "naked-district",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'luke'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c1614eef2346>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mretriever\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mElasticsearchRetriever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocument_store\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdocument_store\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mluke_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nielsr/luke-large\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# luke_model = AutoModel.from_pretrained(\"nielsr/luke-large\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\grizl\\onedrive\\desktop\\ftn\\siap\\fitbot\\venv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"config\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0muse_fast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"use_fast\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\grizl\\onedrive\\desktop\\ftn\\siap\\fitbot\\venv\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"model_type\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[0mconfig_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'luke'"
     ]
    }
   ],
   "source": [
    "# initialize retriever\n",
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "retriever = ElasticsearchRetriever(document_store=document_store)\n",
    "\n",
    "luke_tokenizer = AutoTokenizer.from_pretrained(\"nielsr/luke-large\")\n",
    "\n",
    "# luke_model = AutoModel.from_pretrained(\"nielsr/luke-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "instrumental-vermont",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2021 13:37:46 - INFO - farm.utils -   Using device: CPU \n",
      "03/13/2021 13:37:46 - INFO - farm.utils -   Number of GPUs: 0\n",
      "03/13/2021 13:37:46 - INFO - farm.utils -   Distributed Training: False\n",
      "03/13/2021 13:37:46 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "03/13/2021 13:37:56 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "03/13/2021 13:37:56 - INFO - farm.utils -   Using device: CPU \n",
      "03/13/2021 13:37:56 - INFO - farm.utils -   Number of GPUs: 0\n",
      "03/13/2021 13:37:56 - INFO - farm.utils -   Distributed Training: False\n",
      "03/13/2021 13:37:56 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "03/13/2021 13:37:56 - INFO - farm.infer -   Got ya 11 parallel workers to do inference ...\n",
      "03/13/2021 13:37:56 - INFO - farm.infer -    0    0    0    0    0    0    0    0    0    0    0 \n",
      "03/13/2021 13:37:56 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\\n",
      "03/13/2021 13:37:56 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\\n",
      "03/13/2021 13:37:56 - INFO - farm.infer -                       \n"
     ]
    }
   ],
   "source": [
    "# initialize reader\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "concerned-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "\n",
    "from haystack.pipeline import ExtractiveQAPipeline\n",
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "congressional-integrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2021 13:38:03 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.127s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.84s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.63s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.67s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.67s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.76s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.81s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.89s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.83s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.22s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.28s/ Batches]\n",
      "03/13/2021 13:39:34 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.015s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.55s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.54s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.08s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.94s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:12<00:00,  6.01s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:12<00:00,  6.06s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.95s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.07s/ Batches]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "prediction1 = pipe.run(query=\"What is stamina?\", top_k_retriever=10, top_k_reader=5)\n",
    "\n",
    "prediction2 = pipe.run(query=\"How to avoid injury?\", top_k_retriever=10, top_k_reader=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "solar-california",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 'What is stamina?'\n",
      "[   {   'answer': 'personality trait',\n",
      "        'context': '2-51, Washington DC.</ref>\\n'\n",
      "                   '\\n'\n",
      "                   'Endurance may also refer to an [[Grit (personality '\n",
      "                   'trait)|ability to persevere through a difficult '\n",
      "                   'situation]].\\n'\n",
      "                   '\\n'\n",
      "                   '== Traini'},\n",
      "    {   'answer': 'personality trait',\n",
      "        'context': '2-51, Washington DC.</ref>\\n'\n",
      "                   '\\n'\n",
      "                   'Endurance may also refer to an [[Grit (personality '\n",
      "                   'trait)|ability to persevere through a difficult '\n",
      "                   'situation]].\\n'\n",
      "                   '\\n'\n",
      "                   '== Traini'},\n",
      "    {   'answer': 'the ability of an [[organism]] to exert itself and remain '\n",
      "                  'active for a long period of time',\n",
      "        'context': 'sychological)|hardiness]]) is the ability of an '\n",
      "                   '[[organism]] to exert itself and remain active for a long '\n",
      "                   'period of time, as well as its ability to re'},\n",
      "    {   'answer': 'the ability of an [[organism]] to exert itself and remain '\n",
      "                  'active for a long period of time',\n",
      "        'context': 'sychological)|hardiness]]) is the ability of an '\n",
      "                   '[[organism]] to exert itself and remain active for a long '\n",
      "                   'period of time, as well as its ability to re'},\n",
      "    {   'answer': 'strength',\n",
      "        'context': 'robic]] or [[anaerobic exercise|anaerobic]] ability, i.e. '\n",
      "                   'endurance or strength. A well-rounded fitness program '\n",
      "                   'improves a person in all aspects of fi'}]\n",
      "Question 'How to avoid injury?'\n",
      "[   {   'answer': 'Stretching of the muscles and eccentric training',\n",
      "        'context': 'traditional concentric exercise.<ref name=bubb />\\n'\n",
      "                   '*Stretching of the muscles and eccentric training provides '\n",
      "                   'protection from injury or re-injury.<ref '},\n",
      "    {   'answer': 'Stretching of the muscles and eccentric training',\n",
      "        'context': 'traditional concentric exercise.<ref name=bubb />\\n'\n",
      "                   '*Stretching of the muscles and eccentric training provides '\n",
      "                   'protection from injury or re-injury.<ref '},\n",
      "    {   'answer': 'explosive force',\n",
      "        'context': 'hletes and sports enthusiasts, this eccentric model can '\n",
      "                   'help with [[explosive force]]{{cn|date=August 2020}} '\n",
      "                   'training in order to prevent injuries or '},\n",
      "    {   'answer': 'explosive force',\n",
      "        'context': 'hletes and sports enthusiasts, this eccentric model can '\n",
      "                   'help with [[explosive force]]{{cn|date=August 2020}} '\n",
      "                   'training in order to prevent injuries or '},\n",
      "    {   'answer': 'low-intensity eccentric conditioning',\n",
      "        'context': ' 22344059 }}</ref> Studies done on the elderly show that '\n",
      "                   'low-intensity eccentric conditioning can actually minimize '\n",
      "                   'muscle damage<ref>{{cite journal |'}]\n"
     ]
    }
   ],
   "source": [
    "# get answers\n",
    "print(\"Question 'What is stamina?'\")\n",
    "print_answers(prediction1, details=\"minimal\")\n",
    "print(\"Question 'How to avoid injury?'\")\n",
    "print_answers(prediction2, details=\"minimal\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
