{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "young-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "from haystack.preprocessor.cleaning import clean_wiki_text\n",
    "from haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\n",
    "from haystack.reader.farm import FARMReader\n",
    "from haystack.reader.transformers import TransformersReader\n",
    "from haystack.utils import print_answers\n",
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "increased-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 13:05:16 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:3.667s]\n",
      "04/30/2021 13:05:16 - INFO - elasticsearch -   GET http://localhost:9200/document [status:200 request:0.004s]\n",
      "04/30/2021 13:05:16 - INFO - elasticsearch -   PUT http://localhost:9200/document/_mapping [status:200 request:0.253s]\n",
      "04/30/2021 13:05:16 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.003s]\n"
     ]
    }
   ],
   "source": [
    "# connect to ES, create indexes\n",
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")\n",
    "\n",
    "# to delete created indexes later on use:\n",
    "# curl -XDELETE localhost:9200/label\n",
    "# curl -XDELETE localhost:9200/document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "concerned-inspiration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 13:06:13 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.686s]\n"
     ]
    }
   ],
   "source": [
    "# add data to ES\n",
    "\n",
    "from lxml import etree\n",
    "from lxml.etree import tostring\n",
    "\n",
    "input_file_path = \"data/Wikipedia-Strength-Training.xml\"\n",
    "\n",
    "\n",
    "tree = etree.parse(input_file_path)\n",
    "root = tree.getroot()\n",
    "# iterate through all the titles\n",
    "\n",
    "document_dictionaries = []\n",
    "for text_node in root.findall(\".//text\", namespaces=root.nsmap)[:20]:\n",
    "    document_dictionaries.append({'text': text_node.text, 'meta': None})\n",
    "\n",
    "document_store.write_documents(document_dictionaries)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naked-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize retriever\n",
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "retriever = ElasticsearchRetriever(document_store=document_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "instrumental-vermont",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 13:27:04 - INFO - farm.utils -   Using device: CPU \n",
      "04/30/2021 13:27:04 - INFO - farm.utils -   Number of GPUs: 0\n",
      "04/30/2021 13:27:04 - INFO - farm.utils -   Distributed Training: False\n",
      "04/30/2021 13:27:04 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "04/30/2021 13:27:13 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "04/30/2021 13:27:13 - INFO - farm.utils -   Using device: CPU \n",
      "04/30/2021 13:27:13 - INFO - farm.utils -   Number of GPUs: 0\n",
      "04/30/2021 13:27:13 - INFO - farm.utils -   Distributed Training: False\n",
      "04/30/2021 13:27:13 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "04/30/2021 13:27:13 - INFO - farm.infer -   Got ya 11 parallel workers to do inference ...\n",
      "04/30/2021 13:27:13 - INFO - farm.infer -    0    0    0    0    0    0    0    0    0    0    0 \n",
      "04/30/2021 13:27:13 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\\n",
      "04/30/2021 13:27:13 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\\n",
      "04/30/2021 13:27:13 - INFO - farm.infer -                       \n",
      "04/30/2021 13:27:13 - INFO - farm.utils -   Using device: CPU \n",
      "04/30/2021 13:27:13 - INFO - farm.utils -   Number of GPUs: 0\n",
      "04/30/2021 13:27:13 - INFO - farm.utils -   Distributed Training: False\n",
      "04/30/2021 13:27:13 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "04/30/2021 13:27:13 - INFO - filelock -   Lock 3050333871120 acquired on C:\\Users\\grizl/.cache\\huggingface\\transformers\\fb46db721e5a48679af324906c6b2ac942ae359fd6c7c41940f704678c559b28.26f5a28983ca5d4829732c6f04277c607e503b7ca22e31bbf7113db821212965.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dbd76471204889827974ab2a0dde74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/477 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 13:27:14 - INFO - filelock -   Lock 3050333871120 released on C:\\Users\\grizl/.cache\\huggingface\\transformers\\fb46db721e5a48679af324906c6b2ac942ae359fd6c7c41940f704678c559b28.26f5a28983ca5d4829732c6f04277c607e503b7ca22e31bbf7113db821212965.lock\n",
      "04/30/2021 13:27:15 - INFO - filelock -   Lock 3050348127280 acquired on C:\\Users\\grizl/.cache\\huggingface\\transformers\\9e64fefefaba403b1a8230b21410a483b851458d65f2adf8ab8955084c44a7d5.9528c998736d06b774124cb23b7e6ebd40fc47e06576bfa588b9c049f58462be.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5240eb31b9e74985b4964622ac1f26d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 13:27:20 - INFO - filelock -   Lock 3050348127280 released on C:\\Users\\grizl/.cache\\huggingface\\transformers\\9e64fefefaba403b1a8230b21410a483b851458d65f2adf8ab8955084c44a7d5.9528c998736d06b774124cb23b7e6ebd40fc47e06576bfa588b9c049f58462be.lock\n",
      "04/30/2021 13:27:23 - INFO - filelock -   Lock 3050317805216 acquired on C:\\Users\\grizl/.cache\\huggingface\\transformers\\d6f79d7ce4a278c8df601e9b03444882b4ff0361599d7ee45976386bf254c113.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d954706ec741e2a5dbd4e03b4283b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 13:27:24 - INFO - filelock -   Lock 3050317805216 released on C:\\Users\\grizl/.cache\\huggingface\\transformers\\d6f79d7ce4a278c8df601e9b03444882b4ff0361599d7ee45976386bf254c113.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "04/30/2021 13:27:26 - INFO - filelock -   Lock 3051513035552 acquired on C:\\Users\\grizl/.cache\\huggingface\\transformers\\b9e16424436457ec053ecf35ac0073ecd3b3a558d17198f7a0dda663e42c665b.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6edc7243a141edacdf45b91f9edd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 13:27:26 - INFO - filelock -   Lock 3051513035552 released on C:\\Users\\grizl/.cache\\huggingface\\transformers\\b9e16424436457ec053ecf35ac0073ecd3b3a558d17198f7a0dda663e42c665b.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d.lock\n",
      "04/30/2021 13:27:26 - INFO - filelock -   Lock 3050338187152 acquired on C:\\Users\\grizl/.cache\\huggingface\\transformers\\0b5762f31efa86856f88c656cc0b2dc9f9480e1031ac9b5f38a376a73501779c.6bf2f879cc715e2246d87b2dc885f23d13f8bf9a16a344bad68fd9d22b2378ce.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644407c806cf4e598b23968e9e67f5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/107 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 13:27:27 - INFO - filelock -   Lock 3050338187152 released on C:\\Users\\grizl/.cache\\huggingface\\transformers\\0b5762f31efa86856f88c656cc0b2dc9f9480e1031ac9b5f38a376a73501779c.6bf2f879cc715e2246d87b2dc885f23d13f8bf9a16a344bad68fd9d22b2378ce.lock\n",
      "04/30/2021 13:27:27 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "04/30/2021 13:27:27 - INFO - farm.utils -   Using device: CPU \n",
      "04/30/2021 13:27:27 - INFO - farm.utils -   Number of GPUs: 0\n",
      "04/30/2021 13:27:27 - INFO - farm.utils -   Distributed Training: False\n",
      "04/30/2021 13:27:27 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "04/30/2021 13:27:27 - INFO - farm.infer -   Got ya 11 parallel workers to do inference ...\n",
      "04/30/2021 13:27:27 - INFO - farm.infer -    0    0    0    0    0    0    0    0    0    0    0 \n",
      "04/30/2021 13:27:27 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\\n",
      "04/30/2021 13:27:27 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\\n",
      "04/30/2021 13:27:27 - INFO - farm.infer -                       \n"
     ]
    }
   ],
   "source": [
    "# initialize reader\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)\n",
    "mini_lm_reader = FARMReader(\"deepset/minilm-uncased-squad2\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "concerned-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "\n",
    "from haystack.pipeline import ExtractiveQAPipeline\n",
    "# pipe = ExtractiveQAPipeline(reader, retriever)\n",
    "pipe = ExtractiveQAPipeline(mini_lm_reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "congressional-integrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 13:27:35 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.019s]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.33s/ Batches]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.34s/ Batches]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.30s/ Batches]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.25s/ Batches]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.33s/ Batches]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.34s/ Batches]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/ Batches]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.30s/ Batches]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.37s/ Batches]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.31s/ Batches]\n",
      "04/30/2021 13:27:54 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.023s]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.05 Batches/s]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04 Batches/s]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.06 Batches/s]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.05 Batches/s]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04 Batches/s]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03 Batches/s]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04 Batches/s]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08 Batches/s]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.05 Batches/s]\n",
      "Inferencing Samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.00s/ Batches]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "prediction1 = pipe.run(query=\"What is stamina?\", top_k_retriever=10, top_k_reader=5)\n",
    "\n",
    "prediction2 = pipe.run(query=\"How to avoid injury?\", top_k_retriever=10, top_k_reader=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "solar-california",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 'What is stamina?'\n",
      "[   {   'answer': 'cardiovascular',\n",
      "        'context': 'e=2017-10-08 }}</ref> Although a greater endurance can '\n",
      "                   'assist the [[cardiovascular]] system it does not imply '\n",
      "                   'that any cardiovascular disease can be g'},\n",
      "    {   'answer': 'cardiovascular',\n",
      "        'context': 'e=2017-10-08 }}</ref> Although a greater endurance can '\n",
      "                   'assist the [[cardiovascular]] system it does not imply '\n",
      "                   'that any cardiovascular disease can be g'},\n",
      "    {   'answer': 'cardiovascular',\n",
      "        'context': 'e=2017-10-08 }}</ref> Although a greater endurance can '\n",
      "                   'assist the [[cardiovascular]] system it does not imply '\n",
      "                   'that any cardiovascular disease can be g'},\n",
      "    {   'answer': 'cardiovascular',\n",
      "        'context': 'e=2017-10-08 }}</ref> Although a greater endurance can '\n",
      "                   'assist the [[cardiovascular]] system it does not imply '\n",
      "                   'that any cardiovascular disease can be g'},\n",
      "    {   'answer': 'cardiovascular',\n",
      "        'context': 'e=2017-10-08 }}</ref> Although a greater endurance can '\n",
      "                   'assist the [[cardiovascular]] system it does not imply '\n",
      "                   'that any cardiovascular disease can be g'}]\n",
      "Question 'How to avoid injury?'\n",
      "[   {   'answer': 'manual calculations',\n",
      "        'context': '], hip, knee and ankle. It is common to ignore the wrist '\n",
      "                   'joint in manual calculations. Software intended for such '\n",
      "                   'calculation use the wrist joint also'},\n",
      "    {   'answer': 'manual calculations',\n",
      "        'context': '], hip, knee and ankle. It is common to ignore the wrist '\n",
      "                   'joint in manual calculations. Software intended for such '\n",
      "                   'calculation use the wrist joint also'},\n",
      "    {   'answer': 'manual calculations',\n",
      "        'context': '], hip, knee and ankle. It is common to ignore the wrist '\n",
      "                   'joint in manual calculations. Software intended for such '\n",
      "                   'calculation use the wrist joint also'},\n",
      "    {   'answer': 'manual calculations',\n",
      "        'context': '], hip, knee and ankle. It is common to ignore the wrist '\n",
      "                   'joint in manual calculations. Software intended for such '\n",
      "                   'calculation use the wrist joint also'},\n",
      "    {   'answer': 'manual calculations',\n",
      "        'context': '], hip, knee and ankle. It is common to ignore the wrist '\n",
      "                   'joint in manual calculations. Software intended for such '\n",
      "                   'calculation use the wrist joint also'}]\n"
     ]
    }
   ],
   "source": [
    "# get answers\n",
    "print(\"Question 'What is stamina?'\")\n",
    "print_answers(prediction1, details=\"minimal\")\n",
    "print(\"Question 'How to avoid injury?'\")\n",
    "print_answers(prediction2, details=\"minimal\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
